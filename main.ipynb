{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec4b97b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-27T06:16:00.704513Z",
     "iopub.status.busy": "2025-11-27T06:16:00.704172Z",
     "iopub.status.idle": "2025-11-27T06:16:02.679307Z",
     "shell.execute_reply": "2025-11-27T06:16:02.678204Z"
    },
    "papermill": {
     "duration": 1.98113,
     "end_time": "2025-11-27T06:16:02.680881",
     "exception": false,
     "start_time": "2025-11-27T06:16:00.699751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/job-recom-dataset/datascientist.json\n",
      "/kaggle/input/job-recom-dataset/dataengineer.json\n",
      "/kaggle/input/job-recom-dataset/phpdeveloper.json\n",
      "/kaggle/input/job-recom-dataset/javadeveloper.json\n",
      "/kaggle/input/job-recom-dataset/backenddeveloper.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc80d621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:16:02.688025Z",
     "iopub.status.busy": "2025-11-27T06:16:02.686876Z",
     "iopub.status.idle": "2025-11-27T06:16:02.760608Z",
     "shell.execute_reply": "2025-11-27T06:16:02.759322Z"
    },
    "papermill": {
     "duration": 0.078947,
     "end_time": "2025-11-27T06:16:02.762433",
     "exception": false,
     "start_time": "2025-11-27T06:16:02.683486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting file processing...\n",
      "\n",
      "Reading file: datascientist ...\n",
      "   Data type: List - Items: 32\n",
      "    Success! DataFrame shape: (32, 7)\n",
      "\n",
      "Reading file: dataengineer ...\n",
      "   Data type: List - Items: 80\n",
      "    Success! DataFrame shape: (80, 7)\n",
      "\n",
      "Reading file: phpdeveloper ...\n",
      "   Data type: List - Items: 8\n",
      "    Success! DataFrame shape: (8, 7)\n",
      "\n",
      "Reading file: javadeveloper ...\n",
      "   Data type: List - Items: 20\n",
      "    Success! DataFrame shape: (20, 7)\n",
      "\n",
      "Reading file: backenddeveloper ...\n",
      "   Data type: List - Items: 5\n",
      "    Success! DataFrame shape: (5, 7)\n",
      "\n",
      "========================================\n",
      " Operation Complete! 31 duplicates removed.\n",
      "üìäFinal dataset size: 114 rows\n",
      "========================================\n",
      "                                                link location  \\\n",
      "0  https://sa.indeed.com/rc/clk?jk=02e091c1362581...   Dammam   \n",
      "1  https://sa.indeed.com/rc/clk?jk=3e401a8fae9527...   Dammam   \n",
      "2  https://sa.indeed.com/rc/clk?jk=1d4c0afb83c80a...   Dammam   \n",
      "3  https://sa.indeed.com/rc/clk?jk=e8013b5fc20445...   Dammam   \n",
      "4  https://sa.indeed.com/rc/clk?jk=939bb390f05510...   Jeddah   \n",
      "\n",
      "                title                                       company salary  \\\n",
      "0             Chemist                  Element Materials Technology    NaN   \n",
      "1      Data Scientist                                        Halian    NaN   \n",
      "2  Research Scientist  King Fahd University of Petroleum & Minerals    NaN   \n",
      "3       Administrator                  Element Materials Technology    NaN   \n",
      "4      Data Scientist                                         Salla    NaN   \n",
      "\n",
      "                                                desc       category  \n",
      "0  Overview:\\nElement has an opportunity for a Ch...  datascientist  \n",
      "1  Our Client\\nWe are partnered with one of the l...  datascientist  \n",
      "2  The Applied Research Center for Environment & ...  datascientist  \n",
      "3  Overview:\\nElement has an opportunity for a Ad...  datascientist  \n",
      "4  We are looking for a Data Scientist to design ...  datascientist  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Define file paths\n",
    "file_paths = [\n",
    "    '/kaggle/input/job-recom-dataset/datascientist.json',\n",
    "    '/kaggle/input/job-recom-dataset/dataengineer.json',\n",
    "    '/kaggle/input/job-recom-dataset/phpdeveloper.json',\n",
    "    '/kaggle/input/job-recom-dataset/javadeveloper.json',\n",
    "    '/kaggle/input/job-recom-dataset/backenddeveloper.json'\n",
    "]\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "print(\"üöÄ Starting file processing...\")\n",
    "\n",
    "for path in file_paths:\n",
    "    # Extract category name from filename (e.g., 'datascientist')\n",
    "    filename = os.path.basename(path).replace('.json', '')\n",
    "    print(f\"\\nReading file: {filename} ...\")\n",
    "    \n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # --- Intelligent Data Type Detection ---\n",
    "        temp_df = None\n",
    "        \n",
    "        # Case 1: Data is a list of dictionaries [{}, {}, ...]\n",
    "        if isinstance(data, list):\n",
    "            print(f\"   Data type: List - Items: {len(data)}\")\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            \n",
    "        # Case 2: Data is a dictionary {\"0\": {}, \"1\": {}}\n",
    "        elif isinstance(data, dict):\n",
    "            print(f\"   Data type: Dict - Keys: {len(data)}\")\n",
    "            \n",
    "            # Check for nested 'root' structure if applicable\n",
    "            if \"root\" in data: \n",
    "                 temp_df = pd.DataFrame(data['root'])\n",
    "            else:\n",
    "                 # Standard case: keys are indices, use orient='index'\n",
    "                 temp_df = pd.DataFrame.from_dict(data, orient='index')\n",
    "        \n",
    "        else:\n",
    "            print(f\"   Unknown format: {type(data)}\")\n",
    "            continue\n",
    "\n",
    "        # --- Post-processing the single DataFrame ---\n",
    "        if temp_df is not None and not temp_df.empty:\n",
    "            # Add a 'category' column to track the source\n",
    "            temp_df['category'] = filename \n",
    "            \n",
    "            # Reset index (prevents the \"0\", \"1\" keys from becoming a messy column)\n",
    "            temp_df = temp_df.reset_index(drop=True)\n",
    "            \n",
    "            all_dataframes.append(temp_df)\n",
    "            print(f\"    Success! DataFrame shape: {temp_df.shape}\")\n",
    "        else:\n",
    "            print(\"   DataFrame is empty or could not be created.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Error processing {filename}: {str(e)}\")\n",
    "\n",
    "# --- Final Consolidation ---\n",
    "if all_dataframes:\n",
    "    # Merge all dataframes into one\n",
    "    full_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates based on job description\n",
    "    before_dedup = len(full_df)\n",
    "    full_df = full_df.drop_duplicates(subset=['desc'])\n",
    "    after_dedup = len(full_df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" Operation Complete! {before_dedup - after_dedup} duplicates removed.\")\n",
    "    print(f\"üìäFinal dataset size: {after_dedup} rows\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(full_df.head())\n",
    "else:\n",
    "    print(\"\\n‚ùå No data available to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1b7ac3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:16:02.768967Z",
     "iopub.status.busy": "2025-11-27T06:16:02.768605Z",
     "iopub.status.idle": "2025-11-27T06:16:02.789918Z",
     "shell.execute_reply": "2025-11-27T06:16:02.788647Z"
    },
    "papermill": {
     "duration": 0.026778,
     "end_time": "2025-11-27T06:16:02.791860",
     "exception": false,
     "start_time": "2025-11-27T06:16:02.765082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>desc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=825b2c2507fd95...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Java Developer with Spring experience</td>\n",
       "      <td>Skyline Dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are looking for a Java developer with the f...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>https://sa.indeed.com/company/DITRC/jobs/Odoo-...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Odoo /Python developer</td>\n",
       "      <td>DITRC</td>\n",
       "      <td>$Ÿ¶Ÿ¨Ÿ†Ÿ†Ÿ† ŸÑŸÉŸÑ ÿ¥Ÿáÿ±</td>\n",
       "      <td>We need to hire Odoo /python developer with 5+...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=97d0b0cc657202...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Senior Java Developer</td>\n",
       "      <td>2Soft Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are hiring for one of our Information Techn...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=b4d41df0445355...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Android Development Teaching Assistant (Onsite...</td>\n",
       "      <td>CODING DOJO INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an onsite position to teach students i...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=7357256142f2a2...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Solutions Architect AppDev- Riyadh, KSA</td>\n",
       "      <td>redhat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job\\nThe Red Hat Commercial Sales te...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=2850b8818d6bb2...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Developer</td>\n",
       "      <td>Encore Theme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riyadh, Saudi Arabia\\nTech Hiring\\n2858154\\nJo...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=f81b5f1c6e84ac...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Android Development Associate Instructor (Onsi...</td>\n",
       "      <td>CODING DOJO INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an onsite position to teach students i...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=7959b5d00feff1...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Pega Senior System Architect</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Project Description\\nLuxoft is building a team...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=97e4b19d63954c...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Senior BackEnd Developer - Python</td>\n",
       "      <td>Zid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company Description\\n\\nWho we are?\\n\\nBecome a...</td>\n",
       "      <td>backenddeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=553f2002ecb39f...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Senior Backend Developer</td>\n",
       "      <td>Professional Recruitment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Responsibilities:\\nExperienced backend develop...</td>\n",
       "      <td>backenddeveloper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  link location  \\\n",
       "126  https://sa.indeed.com/rc/clk?jk=825b2c2507fd95...   Riyadh   \n",
       "127  https://sa.indeed.com/company/DITRC/jobs/Odoo-...   Riyadh   \n",
       "132  https://sa.indeed.com/rc/clk?jk=97d0b0cc657202...   Riyadh   \n",
       "133  https://sa.indeed.com/rc/clk?jk=b4d41df0445355...   Riyadh   \n",
       "134  https://sa.indeed.com/rc/clk?jk=7357256142f2a2...   Riyadh   \n",
       "137  https://sa.indeed.com/rc/clk?jk=2850b8818d6bb2...   Riyadh   \n",
       "138  https://sa.indeed.com/rc/clk?jk=f81b5f1c6e84ac...   Riyadh   \n",
       "139  https://sa.indeed.com/rc/clk?jk=7959b5d00feff1...   Riyadh   \n",
       "140  https://sa.indeed.com/rc/clk?jk=97e4b19d63954c...   Riyadh   \n",
       "141  https://sa.indeed.com/rc/clk?jk=553f2002ecb39f...   Riyadh   \n",
       "\n",
       "                                                 title  \\\n",
       "126              Java Developer with Spring experience   \n",
       "127                             Odoo /Python developer   \n",
       "132                              Senior Java Developer   \n",
       "133  Android Development Teaching Assistant (Onsite...   \n",
       "134            Solutions Architect AppDev- Riyadh, KSA   \n",
       "137                                          Developer   \n",
       "138  Android Development Associate Instructor (Onsi...   \n",
       "139                       Pega Senior System Architect   \n",
       "140                  Senior BackEnd Developer - Python   \n",
       "141                           Senior Backend Developer   \n",
       "\n",
       "                      company          salary  \\\n",
       "126          Skyline Dynamics             NaN   \n",
       "127                     DITRC  $Ÿ¶Ÿ¨Ÿ†Ÿ†Ÿ† ŸÑŸÉŸÑ ÿ¥Ÿáÿ±   \n",
       "132           2Soft Solutions             NaN   \n",
       "133           CODING DOJO INC             NaN   \n",
       "134                    redhat             NaN   \n",
       "137              Encore Theme             NaN   \n",
       "138           CODING DOJO INC             NaN   \n",
       "139                    Luxoft             NaN   \n",
       "140                       Zid             NaN   \n",
       "141  Professional Recruitment             NaN   \n",
       "\n",
       "                                                  desc          category  \n",
       "126  We are looking for a Java developer with the f...     javadeveloper  \n",
       "127  We need to hire Odoo /python developer with 5+...     javadeveloper  \n",
       "132  We are hiring for one of our Information Techn...     javadeveloper  \n",
       "133  This is an onsite position to teach students i...     javadeveloper  \n",
       "134  About the job\\nThe Red Hat Commercial Sales te...     javadeveloper  \n",
       "137  Riyadh, Saudi Arabia\\nTech Hiring\\n2858154\\nJo...     javadeveloper  \n",
       "138  This is an onsite position to teach students i...     javadeveloper  \n",
       "139  Project Description\\nLuxoft is building a team...     javadeveloper  \n",
       "140  Company Description\\n\\nWho we are?\\n\\nBecome a...  backenddeveloper  \n",
       "141  Responsibilities:\\nExperienced backend develop...  backenddeveloper  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92984fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:16:02.800041Z",
     "iopub.status.busy": "2025-11-27T06:16:02.799711Z",
     "iopub.status.idle": "2025-11-27T06:16:02.811632Z",
     "shell.execute_reply": "2025-11-27T06:16:02.810710Z"
    },
    "papermill": {
     "duration": 0.01779,
     "end_time": "2025-11-27T06:16:02.813161",
     "exception": false,
     "start_time": "2025-11-27T06:16:02.795371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>desc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=02e091c1362581...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Chemist</td>\n",
       "      <td>Element Materials Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overview:\\nElement has an opportunity for a Ch...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=3e401a8fae9527...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Halian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Client\\nWe are partnered with one of the l...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=1d4c0afb83c80a...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>King Fahd University of Petroleum &amp; Minerals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Applied Research Center for Environment &amp; ...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=e8013b5fc20445...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Administrator</td>\n",
       "      <td>Element Materials Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overview:\\nElement has an opportunity for a Ad...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=939bb390f05510...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Salla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are looking for a Data Scientist to design ...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=341a7df5a4122d...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Halian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Client\\nWe are partnered with one of the l...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=fb99a740b741d4...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Senior Construction Manager</td>\n",
       "      <td>Scientific Research Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The new construction of site improvements and ...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=8c9f296de49be1...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Senior Environmental scientist</td>\n",
       "      <td>AECOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a KSA Intermediate Terrestrial Ecologist II...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=2abff331d63906...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Secretary</td>\n",
       "      <td>Worley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company : Worley\\nPrimary Location\\n: SAU-ARD-...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=6324c7847644c4...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Project Engineer</td>\n",
       "      <td>Worley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company : Worley\\nPrimary Location\\n: SAU-ARD-...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link location  \\\n",
       "0  https://sa.indeed.com/rc/clk?jk=02e091c1362581...   Dammam   \n",
       "1  https://sa.indeed.com/rc/clk?jk=3e401a8fae9527...   Dammam   \n",
       "2  https://sa.indeed.com/rc/clk?jk=1d4c0afb83c80a...   Dammam   \n",
       "3  https://sa.indeed.com/rc/clk?jk=e8013b5fc20445...   Dammam   \n",
       "4  https://sa.indeed.com/rc/clk?jk=939bb390f05510...   Jeddah   \n",
       "5  https://sa.indeed.com/rc/clk?jk=341a7df5a4122d...   Jeddah   \n",
       "6  https://sa.indeed.com/rc/clk?jk=fb99a740b741d4...   Jeddah   \n",
       "7  https://sa.indeed.com/rc/clk?jk=8c9f296de49be1...   Jeddah   \n",
       "8  https://sa.indeed.com/rc/clk?jk=2abff331d63906...   Riyadh   \n",
       "9  https://sa.indeed.com/rc/clk?jk=6324c7847644c4...   Riyadh   \n",
       "\n",
       "                            title  \\\n",
       "0                         Chemist   \n",
       "1                  Data Scientist   \n",
       "2              Research Scientist   \n",
       "3                   Administrator   \n",
       "4                  Data Scientist   \n",
       "5                  Data Scientist   \n",
       "6     Senior Construction Manager   \n",
       "7  Senior Environmental scientist   \n",
       "8                       Secretary   \n",
       "9                Project Engineer   \n",
       "\n",
       "                                        company salary  \\\n",
       "0                  Element Materials Technology    NaN   \n",
       "1                                        Halian    NaN   \n",
       "2  King Fahd University of Petroleum & Minerals    NaN   \n",
       "3                  Element Materials Technology    NaN   \n",
       "4                                         Salla    NaN   \n",
       "5                                        Halian    NaN   \n",
       "6               Scientific Research Corporation    NaN   \n",
       "7                                         AECOM    NaN   \n",
       "8                                        Worley    NaN   \n",
       "9                                        Worley    NaN   \n",
       "\n",
       "                                                desc       category  \n",
       "0  Overview:\\nElement has an opportunity for a Ch...  datascientist  \n",
       "1  Our Client\\nWe are partnered with one of the l...  datascientist  \n",
       "2  The Applied Research Center for Environment & ...  datascientist  \n",
       "3  Overview:\\nElement has an opportunity for a Ad...  datascientist  \n",
       "4  We are looking for a Data Scientist to design ...  datascientist  \n",
       "5  Our Client\\nWe are partnered with one of the l...  datascientist  \n",
       "6  The new construction of site improvements and ...  datascientist  \n",
       "7  As a KSA Intermediate Terrestrial Ecologist II...  datascientist  \n",
       "8  Company : Worley\\nPrimary Location\\n: SAU-ARD-...  datascientist  \n",
       "9  Company : Worley\\nPrimary Location\\n: SAU-ARD-...  datascientist  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36e520",
   "metadata": {
    "papermill": {
     "duration": 0.002876,
     "end_time": "2025-11-27T06:16:02.819154",
     "exception": false,
     "start_time": "2025-11-27T06:16:02.816278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- using richer dataset!\n",
    "- Collect Persian (Multilingual language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25ef3edd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:16:02.826252Z",
     "iopub.status.busy": "2025-11-27T06:16:02.825936Z",
     "iopub.status.idle": "2025-11-27T06:16:05.335368Z",
     "shell.execute_reply": "2025-11-27T06:16:05.334005Z"
    },
    "papermill": {
     "duration": 2.514958,
     "end_time": "2025-11-27T06:16:05.336883",
     "exception": false,
     "start_time": "2025-11-27T06:16:02.821925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Starting text cleaning process...\n",
      "‚úÖ Text cleaning completed.\n",
      "\n",
      "==================================================\n",
      "üîç Comparison: Raw vs Cleaned\n",
      "==================================================\n",
      "--- ORIGINAL DESC ---\n",
      "Overview:\n",
      "Element has an opportunity for a Chemistry Technician for testing, sample preparation and delivery/collection of samples and preparation of test reports\n",
      "\n",
      "This position will be based in Dammam , KSA\n",
      "\n",
      "Responsibilities:\n",
      "Analysis of water, soil, aggregates, concrete and scale samples ,operatin...\n",
      "\n",
      "--- CLEANED DESC ---\n",
      "overview element opportunity chemistry technician testing sample preparation delivery collection samples preparation test reports position based dammam ksa responsibilities analysis water soil aggregates concrete scale samples operating equipments like ph ec tds meters uv visible spectrophotometers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 1. Download necessary NLTK resources\n",
    "# (If you are running this offline, you might need to download these manually once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 2. Define the cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies the following pre-processing steps:\n",
    "    1. Lowercasing\n",
    "    2. Removing HTML tags\n",
    "    3. Removing non-ASCII characters\n",
    "    4. Substitution (removing newlines/tabs)\n",
    "    5. Removing punctuation\n",
    "    6. Removing stop words\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing HTML tags (Regex to find <...>)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Removing non-ASCII characters (Keep only standard characters)\n",
    "    # This removes emojis or weird formatting characters\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r' ', text)\n",
    "    \n",
    "    # Substitution (Replace newlines \\n and tabs \\t with a single space)\n",
    "    text = re.sub(r'[\\r\\n\\t]+', ' ', text)\n",
    "    \n",
    "    # Removing Punctuation\n",
    "    # We replace punctuation with spaces to avoid merging words (e.g. \"hello/world\" -> \"hello world\")\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    \n",
    "    # F. Removing Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Tokenize by splitting on whitespace\n",
    "    words = text.split()\n",
    "    # Filter out stop words\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    \n",
    "    # Join back into a single string\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# 3. Apply the function to the 'desc' column\n",
    "print(\"üßπ Starting text cleaning process...\")\n",
    "\n",
    "# We create a NEW column 'cleaned_desc' to preserve the original data for comparison\n",
    "full_df['cleaned_desc'] = full_df['desc'].apply(clean_text)\n",
    "\n",
    "print(\"‚úÖ Text cleaning completed.\")\n",
    "\n",
    "# 4. Verify the results (Compare Before vs After)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîç Comparison: Raw vs Cleaned\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# displaying the first valid entry\n",
    "sample_row = full_df.iloc[0]\n",
    "print(f\"--- ORIGINAL DESC ---\\n{sample_row['desc'][:300]}...\") # Show first 300 chars\n",
    "print(f\"\\n--- CLEANED DESC ---\\n{sample_row['cleaned_desc'][:300]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0223c648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:16:05.345248Z",
     "iopub.status.busy": "2025-11-27T06:16:05.344821Z",
     "iopub.status.idle": "2025-11-27T06:16:20.616532Z",
     "shell.execute_reply": "2025-11-27T06:16:20.615220Z"
    },
    "papermill": {
     "duration": 15.278091,
     "end_time": "2025-11-27T06:16:20.618130",
     "exception": false,
     "start_time": "2025-11-27T06:16:05.340039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing Custom NER Training (Correction applied)...\n",
      "\n",
      "Running training epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/thinc/layers/layernorm.py:31: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  d_xhat = N * dY - sum_dy - dist * var ** (-1.0) * sum_dy_dist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Epoch 5: Loss = 37.88\n",
      "   Epoch 10: Loss = 25.10\n",
      "   Epoch 15: Loss = 15.06\n",
      "   Epoch 20: Loss = 18.34\n",
      "   Epoch 25: Loss = 9.83\n",
      "   Epoch 30: Loss = 3.26\n",
      "Training Completed.\n",
      "\n",
      "üîç Applying NER to the Job Dataset...\n",
      "\n",
      "==================================================\n",
      "SAMPLE EXTRACTIONS\n",
      "==================================================\n",
      "        category                                 extracted_entities\n",
      "0  datascientist                         [(6, SKILL), (30, DEGREE)]\n",
      "1  datascientist  [(data scientist, ROLE), (data science, ROLE),...\n",
      "2  datascientist  [(3, SKILL), (30 days, ROLE), (6, SKILL), (9, ...\n",
      "3  datascientist                         [(6, SKILL), (30, DEGREE)]\n",
      "4  datascientist  [(data assessing, ROLE), (data, SKILL), (data,...\n",
      "5  datascientist  [(data scientist, ROLE), (data science, ROLE),...\n",
      "6  datascientist  [(60, SKILL), (rm, SKILL), (cor, SKILL), (1, S...\n",
      "7  datascientist                                                 []\n",
      "8  datascientist  [(21, SKILL), (2022 unposting, ROLE), (2022 re...\n",
      "9  datascientist  [(2022, DEGREE), (14, DEGREE), (2022 reporting...\n",
      "\n",
      "Total entities extracted: 270\n",
      "Sample entities: [('6', 'SKILL'), ('30', 'DEGREE'), ('data scientist', 'ROLE'), ('data science', 'ROLE'), ('data', 'SKILL')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# 1. DEFINE THE TRAINING DATA (CORRECTED INDICES - NO OVERLAPS)\n",
    "TRAIN_DATA = [\n",
    "    # \"Senior\" is skipped, \"Java\" is SKILL, \"Developer\" is ROLE, \"AWS\" is SKILL\n",
    "    (\"We need a Senior Java Developer with AWS experience.\", \n",
    "     {\"entities\": [(17, 21, \"SKILL\"), (22, 31, \"ROLE\"), (37, 40, \"SKILL\")]}),\n",
    "     \n",
    "    # \"Data Scientist\" is ROLE, \"Python\" is SKILL, \"SQL\" is SKILL\n",
    "    (\"Looking for a Data Scientist proficient in Python and SQL.\", \n",
    "     {\"entities\": [(14, 28, \"ROLE\"), (43, 49, \"SKILL\"), (54, 57, \"SKILL\")]}),\n",
    "     \n",
    "    # \"Bachelor\" is DEGREE, \"Computer Science\" is MAJOR\n",
    "    (\"Must have a Bachelor degree in Computer Science.\", \n",
    "     {\"entities\": [(12, 20, \"DEGREE\"), (31, 47, \"MAJOR\")]}),\n",
    "     \n",
    "    # \"Machine Learning\" is SKILL, \"Deep Learning\" is SKILL\n",
    "    (\"Experience with Machine Learning and Deep Learning is a plus.\", \n",
    "     {\"entities\": [(16, 32, \"SKILL\"), (37, 50, \"SKILL\")]}),\n",
    "     \n",
    "    # \"PHP Developer\" is ROLE, \"backend\" could be SKILL/CAT\n",
    "    (\"We are hiring a PHP Developer for our backend team.\", \n",
    "     {\"entities\": [(16, 29, \"ROLE\")]}),\n",
    "     \n",
    "    # \"React\" SKILL, \"Node.js\" SKILL, \"MongoDB\" SKILL\n",
    "    (\"Knowledge of React, Node.js and MongoDB required.\", \n",
    "     {\"entities\": [(13, 18, \"SKILL\"), (20, 27, \"SKILL\"), (32, 39, \"SKILL\")]}),\n",
    "     \n",
    "    # \"Masters\" DEGREE, \"Artificial Intelligence\" MAJOR\n",
    "    (\"Masters in Artificial Intelligence preferred.\", \n",
    "     {\"entities\": [(0, 7, \"DEGREE\"), (11, 34, \"MAJOR\")]}),\n",
    "     \n",
    "    # \"C++\" SKILL, \"Java\" SKILL\n",
    "    (\"Strong background in C++ and Java.\", \n",
    "     {\"entities\": [(21, 24, \"SKILL\"), (29, 33, \"SKILL\")]}),\n",
    "     \n",
    "    # \"Backend Engineer\" ROLE\n",
    "    (\"Junior Backend Engineer needed immediately.\", \n",
    "     {\"entities\": [(7, 23, \"ROLE\")]}),\n",
    "     \n",
    "    # \"Tableau\" SKILL, \"PowerBI\" SKILL\n",
    "    (\"Proficiency in Tableau and PowerBI.\", \n",
    "     {\"entities\": [(15, 22, \"SKILL\"), (27, 34, \"SKILL\")]})\n",
    "]\n",
    "\n",
    "print(\"initializing Custom NER Training (Correction applied)...\")\n",
    "\n",
    "# INITIALIZE THE BLANK MODEL\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create the NER pipeline\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Add labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# 3. THE TRAINING LOOP\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    \n",
    "    print(\"\\nRunning training epochs...\")\n",
    "    \n",
    "    for itn in range(30): # Increased epochs slightly for better convergence\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        \n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        \n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            \n",
    "            example_batch = []\n",
    "            for text, ann in zip(texts, annotations):\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, ann)\n",
    "                example_batch.append(example)\n",
    "            \n",
    "            nlp.update(example_batch, drop=0.3, losses=losses) # Lowered dropout slightly\n",
    "        \n",
    "        if (itn + 1) % 5 == 0:\n",
    "            print(f\"   Epoch {itn + 1}: Loss = {losses['ner']:.2f}\")\n",
    "\n",
    "print(\"Training Completed.\")\n",
    "\n",
    "# APPLY TO OUR DATASET\n",
    "def extract_entities(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    doc = nlp(text)\n",
    "    # Return a dict or list of found entities\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "print(\"\\nüîç Applying NER to the Job Dataset...\")\n",
    "full_df['extracted_entities'] = full_df['cleaned_desc'].apply(extract_entities)\n",
    "\n",
    "# VIEW RESULTS\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAMPLE EXTRACTIONS\")\n",
    "print(\"=\"*50)\n",
    "print(full_df[['category', 'extracted_entities']].head(10))\n",
    "\n",
    "# Count stats\n",
    "all_ents = [ent for sublist in full_df['extracted_entities'] for ent in sublist]\n",
    "print(f\"\\nTotal entities extracted: {len(all_ents)}\")\n",
    "if len(all_ents) > 0:\n",
    "    print(f\"Sample entities: {all_ents[:5]}\")\n",
    "else:\n",
    "    print(\"No entities found. (This is expected if the dataset vocabulary doesn't overlap with our tiny training set)\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8835435,
     "sourceId": 13867576,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.272069,
   "end_time": "2025-11-27T06:16:23.008714",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-27T06:15:55.736645",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
