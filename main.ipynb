{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe758926",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-27T06:44:28.280228Z",
     "iopub.status.busy": "2025-11-27T06:44:28.279364Z",
     "iopub.status.idle": "2025-11-27T06:44:30.087401Z",
     "shell.execute_reply": "2025-11-27T06:44:30.086345Z"
    },
    "papermill": {
     "duration": 1.813732,
     "end_time": "2025-11-27T06:44:30.088951",
     "exception": false,
     "start_time": "2025-11-27T06:44:28.275219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/job-recom-dataset/datascientist.json\n",
      "/kaggle/input/job-recom-dataset/dataengineer.json\n",
      "/kaggle/input/job-recom-dataset/phpdeveloper.json\n",
      "/kaggle/input/job-recom-dataset/javadeveloper.json\n",
      "/kaggle/input/job-recom-dataset/backenddeveloper.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073afa85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:44:30.095308Z",
     "iopub.status.busy": "2025-11-27T06:44:30.094913Z",
     "iopub.status.idle": "2025-11-27T06:44:30.177564Z",
     "shell.execute_reply": "2025-11-27T06:44:30.176518Z"
    },
    "papermill": {
     "duration": 0.087621,
     "end_time": "2025-11-27T06:44:30.179117",
     "exception": false,
     "start_time": "2025-11-27T06:44:30.091496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting file processing...\n",
      "\n",
      "Reading file: datascientist ...\n",
      "   Data type: List - Items: 32\n",
      "    Success! DataFrame shape: (32, 7)\n",
      "\n",
      "Reading file: dataengineer ...\n",
      "   Data type: List - Items: 80\n",
      "    Success! DataFrame shape: (80, 7)\n",
      "\n",
      "Reading file: phpdeveloper ...\n",
      "   Data type: List - Items: 8\n",
      "    Success! DataFrame shape: (8, 7)\n",
      "\n",
      "Reading file: javadeveloper ...\n",
      "   Data type: List - Items: 20\n",
      "    Success! DataFrame shape: (20, 7)\n",
      "\n",
      "Reading file: backenddeveloper ...\n",
      "   Data type: List - Items: 5\n",
      "    Success! DataFrame shape: (5, 7)\n",
      "\n",
      "========================================\n",
      " Operation Complete! 31 duplicates removed.\n",
      "üìäFinal dataset size: 114 rows\n",
      "========================================\n",
      "                                                link location  \\\n",
      "0  https://sa.indeed.com/rc/clk?jk=02e091c1362581...   Dammam   \n",
      "1  https://sa.indeed.com/rc/clk?jk=3e401a8fae9527...   Dammam   \n",
      "2  https://sa.indeed.com/rc/clk?jk=1d4c0afb83c80a...   Dammam   \n",
      "3  https://sa.indeed.com/rc/clk?jk=e8013b5fc20445...   Dammam   \n",
      "4  https://sa.indeed.com/rc/clk?jk=939bb390f05510...   Jeddah   \n",
      "\n",
      "                title                                       company salary  \\\n",
      "0             Chemist                  Element Materials Technology    NaN   \n",
      "1      Data Scientist                                        Halian    NaN   \n",
      "2  Research Scientist  King Fahd University of Petroleum & Minerals    NaN   \n",
      "3       Administrator                  Element Materials Technology    NaN   \n",
      "4      Data Scientist                                         Salla    NaN   \n",
      "\n",
      "                                                desc       category  \n",
      "0  Overview:\\nElement has an opportunity for a Ch...  datascientist  \n",
      "1  Our Client\\nWe are partnered with one of the l...  datascientist  \n",
      "2  The Applied Research Center for Environment & ...  datascientist  \n",
      "3  Overview:\\nElement has an opportunity for a Ad...  datascientist  \n",
      "4  We are looking for a Data Scientist to design ...  datascientist  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Define file paths\n",
    "file_paths = [\n",
    "    '/kaggle/input/job-recom-dataset/datascientist.json',\n",
    "    '/kaggle/input/job-recom-dataset/dataengineer.json',\n",
    "    '/kaggle/input/job-recom-dataset/phpdeveloper.json',\n",
    "    '/kaggle/input/job-recom-dataset/javadeveloper.json',\n",
    "    '/kaggle/input/job-recom-dataset/backenddeveloper.json'\n",
    "]\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "print(\"üöÄ Starting file processing...\")\n",
    "\n",
    "for path in file_paths:\n",
    "    # Extract category name from filename (e.g., 'datascientist')\n",
    "    filename = os.path.basename(path).replace('.json', '')\n",
    "    print(f\"\\nReading file: {filename} ...\")\n",
    "    \n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # --- Intelligent Data Type Detection ---\n",
    "        temp_df = None\n",
    "        \n",
    "        # Case 1: Data is a list of dictionaries [{}, {}, ...]\n",
    "        if isinstance(data, list):\n",
    "            print(f\"   Data type: List - Items: {len(data)}\")\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            \n",
    "        # Case 2: Data is a dictionary {\"0\": {}, \"1\": {}}\n",
    "        elif isinstance(data, dict):\n",
    "            print(f\"   Data type: Dict - Keys: {len(data)}\")\n",
    "            \n",
    "            # Check for nested 'root' structure if applicable\n",
    "            if \"root\" in data: \n",
    "                 temp_df = pd.DataFrame(data['root'])\n",
    "            else:\n",
    "                 # Standard case: keys are indices, use orient='index'\n",
    "                 temp_df = pd.DataFrame.from_dict(data, orient='index')\n",
    "        \n",
    "        else:\n",
    "            print(f\"   Unknown format: {type(data)}\")\n",
    "            continue\n",
    "\n",
    "        # --- Post-processing the single DataFrame ---\n",
    "        if temp_df is not None and not temp_df.empty:\n",
    "            # Add a 'category' column to track the source\n",
    "            temp_df['category'] = filename \n",
    "            \n",
    "            # Reset index (prevents the \"0\", \"1\" keys from becoming a messy column)\n",
    "            temp_df = temp_df.reset_index(drop=True)\n",
    "            \n",
    "            all_dataframes.append(temp_df)\n",
    "            print(f\"    Success! DataFrame shape: {temp_df.shape}\")\n",
    "        else:\n",
    "            print(\"   DataFrame is empty or could not be created.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   Error processing {filename}: {str(e)}\")\n",
    "\n",
    "# --- Final Consolidation ---\n",
    "if all_dataframes:\n",
    "    # Merge all dataframes into one\n",
    "    full_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates based on job description\n",
    "    before_dedup = len(full_df)\n",
    "    full_df = full_df.drop_duplicates(subset=['desc'])\n",
    "    after_dedup = len(full_df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\" Operation Complete! {before_dedup - after_dedup} duplicates removed.\")\n",
    "    print(f\"üìäFinal dataset size: {after_dedup} rows\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Display the first few rows\n",
    "    print(full_df.head())\n",
    "else:\n",
    "    print(\"\\n‚ùå No data available to merge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9d73e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:44:30.185511Z",
     "iopub.status.busy": "2025-11-27T06:44:30.184771Z",
     "iopub.status.idle": "2025-11-27T06:44:30.203099Z",
     "shell.execute_reply": "2025-11-27T06:44:30.202291Z"
    },
    "papermill": {
     "duration": 0.02297,
     "end_time": "2025-11-27T06:44:30.204551",
     "exception": false,
     "start_time": "2025-11-27T06:44:30.181581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>desc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=825b2c2507fd95...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Java Developer with Spring experience</td>\n",
       "      <td>Skyline Dynamics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are looking for a Java developer with the f...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>https://sa.indeed.com/company/DITRC/jobs/Odoo-...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Odoo /Python developer</td>\n",
       "      <td>DITRC</td>\n",
       "      <td>$Ÿ¶Ÿ¨Ÿ†Ÿ†Ÿ† ŸÑŸÉŸÑ ÿ¥Ÿáÿ±</td>\n",
       "      <td>We need to hire Odoo /python developer with 5+...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=97d0b0cc657202...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Senior Java Developer</td>\n",
       "      <td>2Soft Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are hiring for one of our Information Techn...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=b4d41df0445355...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Android Development Teaching Assistant (Onsite...</td>\n",
       "      <td>CODING DOJO INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an onsite position to teach students i...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=7357256142f2a2...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Solutions Architect AppDev- Riyadh, KSA</td>\n",
       "      <td>redhat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About the job\\nThe Red Hat Commercial Sales te...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=2850b8818d6bb2...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Developer</td>\n",
       "      <td>Encore Theme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Riyadh, Saudi Arabia\\nTech Hiring\\n2858154\\nJo...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=f81b5f1c6e84ac...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Android Development Associate Instructor (Onsi...</td>\n",
       "      <td>CODING DOJO INC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an onsite position to teach students i...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=7959b5d00feff1...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Pega Senior System Architect</td>\n",
       "      <td>Luxoft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Project Description\\nLuxoft is building a team...</td>\n",
       "      <td>javadeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=97e4b19d63954c...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Senior BackEnd Developer - Python</td>\n",
       "      <td>Zid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company Description\\n\\nWho we are?\\n\\nBecome a...</td>\n",
       "      <td>backenddeveloper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=553f2002ecb39f...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Senior Backend Developer</td>\n",
       "      <td>Professional Recruitment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Responsibilities:\\nExperienced backend develop...</td>\n",
       "      <td>backenddeveloper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  link location  \\\n",
       "126  https://sa.indeed.com/rc/clk?jk=825b2c2507fd95...   Riyadh   \n",
       "127  https://sa.indeed.com/company/DITRC/jobs/Odoo-...   Riyadh   \n",
       "132  https://sa.indeed.com/rc/clk?jk=97d0b0cc657202...   Riyadh   \n",
       "133  https://sa.indeed.com/rc/clk?jk=b4d41df0445355...   Riyadh   \n",
       "134  https://sa.indeed.com/rc/clk?jk=7357256142f2a2...   Riyadh   \n",
       "137  https://sa.indeed.com/rc/clk?jk=2850b8818d6bb2...   Riyadh   \n",
       "138  https://sa.indeed.com/rc/clk?jk=f81b5f1c6e84ac...   Riyadh   \n",
       "139  https://sa.indeed.com/rc/clk?jk=7959b5d00feff1...   Riyadh   \n",
       "140  https://sa.indeed.com/rc/clk?jk=97e4b19d63954c...   Riyadh   \n",
       "141  https://sa.indeed.com/rc/clk?jk=553f2002ecb39f...   Riyadh   \n",
       "\n",
       "                                                 title  \\\n",
       "126              Java Developer with Spring experience   \n",
       "127                             Odoo /Python developer   \n",
       "132                              Senior Java Developer   \n",
       "133  Android Development Teaching Assistant (Onsite...   \n",
       "134            Solutions Architect AppDev- Riyadh, KSA   \n",
       "137                                          Developer   \n",
       "138  Android Development Associate Instructor (Onsi...   \n",
       "139                       Pega Senior System Architect   \n",
       "140                  Senior BackEnd Developer - Python   \n",
       "141                           Senior Backend Developer   \n",
       "\n",
       "                      company          salary  \\\n",
       "126          Skyline Dynamics             NaN   \n",
       "127                     DITRC  $Ÿ¶Ÿ¨Ÿ†Ÿ†Ÿ† ŸÑŸÉŸÑ ÿ¥Ÿáÿ±   \n",
       "132           2Soft Solutions             NaN   \n",
       "133           CODING DOJO INC             NaN   \n",
       "134                    redhat             NaN   \n",
       "137              Encore Theme             NaN   \n",
       "138           CODING DOJO INC             NaN   \n",
       "139                    Luxoft             NaN   \n",
       "140                       Zid             NaN   \n",
       "141  Professional Recruitment             NaN   \n",
       "\n",
       "                                                  desc          category  \n",
       "126  We are looking for a Java developer with the f...     javadeveloper  \n",
       "127  We need to hire Odoo /python developer with 5+...     javadeveloper  \n",
       "132  We are hiring for one of our Information Techn...     javadeveloper  \n",
       "133  This is an onsite position to teach students i...     javadeveloper  \n",
       "134  About the job\\nThe Red Hat Commercial Sales te...     javadeveloper  \n",
       "137  Riyadh, Saudi Arabia\\nTech Hiring\\n2858154\\nJo...     javadeveloper  \n",
       "138  This is an onsite position to teach students i...     javadeveloper  \n",
       "139  Project Description\\nLuxoft is building a team...     javadeveloper  \n",
       "140  Company Description\\n\\nWho we are?\\n\\nBecome a...  backenddeveloper  \n",
       "141  Responsibilities:\\nExperienced backend develop...  backenddeveloper  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9fa74b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:44:30.211536Z",
     "iopub.status.busy": "2025-11-27T06:44:30.210801Z",
     "iopub.status.idle": "2025-11-27T06:44:30.221918Z",
     "shell.execute_reply": "2025-11-27T06:44:30.221140Z"
    },
    "papermill": {
     "duration": 0.015995,
     "end_time": "2025-11-27T06:44:30.223343",
     "exception": false,
     "start_time": "2025-11-27T06:44:30.207348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>desc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=02e091c1362581...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Chemist</td>\n",
       "      <td>Element Materials Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overview:\\nElement has an opportunity for a Ch...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=3e401a8fae9527...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Halian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Client\\nWe are partnered with one of the l...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=1d4c0afb83c80a...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>King Fahd University of Petroleum &amp; Minerals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Applied Research Center for Environment &amp; ...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=e8013b5fc20445...</td>\n",
       "      <td>Dammam</td>\n",
       "      <td>Administrator</td>\n",
       "      <td>Element Materials Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Overview:\\nElement has an opportunity for a Ad...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=939bb390f05510...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Salla</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are looking for a Data Scientist to design ...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=341a7df5a4122d...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Halian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Client\\nWe are partnered with one of the l...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=fb99a740b741d4...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Senior Construction Manager</td>\n",
       "      <td>Scientific Research Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The new construction of site improvements and ...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=8c9f296de49be1...</td>\n",
       "      <td>Jeddah</td>\n",
       "      <td>Senior Environmental scientist</td>\n",
       "      <td>AECOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a KSA Intermediate Terrestrial Ecologist II...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=2abff331d63906...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Secretary</td>\n",
       "      <td>Worley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company : Worley\\nPrimary Location\\n: SAU-ARD-...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://sa.indeed.com/rc/clk?jk=6324c7847644c4...</td>\n",
       "      <td>Riyadh</td>\n",
       "      <td>Project Engineer</td>\n",
       "      <td>Worley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company : Worley\\nPrimary Location\\n: SAU-ARD-...</td>\n",
       "      <td>datascientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link location  \\\n",
       "0  https://sa.indeed.com/rc/clk?jk=02e091c1362581...   Dammam   \n",
       "1  https://sa.indeed.com/rc/clk?jk=3e401a8fae9527...   Dammam   \n",
       "2  https://sa.indeed.com/rc/clk?jk=1d4c0afb83c80a...   Dammam   \n",
       "3  https://sa.indeed.com/rc/clk?jk=e8013b5fc20445...   Dammam   \n",
       "4  https://sa.indeed.com/rc/clk?jk=939bb390f05510...   Jeddah   \n",
       "5  https://sa.indeed.com/rc/clk?jk=341a7df5a4122d...   Jeddah   \n",
       "6  https://sa.indeed.com/rc/clk?jk=fb99a740b741d4...   Jeddah   \n",
       "7  https://sa.indeed.com/rc/clk?jk=8c9f296de49be1...   Jeddah   \n",
       "8  https://sa.indeed.com/rc/clk?jk=2abff331d63906...   Riyadh   \n",
       "9  https://sa.indeed.com/rc/clk?jk=6324c7847644c4...   Riyadh   \n",
       "\n",
       "                            title  \\\n",
       "0                         Chemist   \n",
       "1                  Data Scientist   \n",
       "2              Research Scientist   \n",
       "3                   Administrator   \n",
       "4                  Data Scientist   \n",
       "5                  Data Scientist   \n",
       "6     Senior Construction Manager   \n",
       "7  Senior Environmental scientist   \n",
       "8                       Secretary   \n",
       "9                Project Engineer   \n",
       "\n",
       "                                        company salary  \\\n",
       "0                  Element Materials Technology    NaN   \n",
       "1                                        Halian    NaN   \n",
       "2  King Fahd University of Petroleum & Minerals    NaN   \n",
       "3                  Element Materials Technology    NaN   \n",
       "4                                         Salla    NaN   \n",
       "5                                        Halian    NaN   \n",
       "6               Scientific Research Corporation    NaN   \n",
       "7                                         AECOM    NaN   \n",
       "8                                        Worley    NaN   \n",
       "9                                        Worley    NaN   \n",
       "\n",
       "                                                desc       category  \n",
       "0  Overview:\\nElement has an opportunity for a Ch...  datascientist  \n",
       "1  Our Client\\nWe are partnered with one of the l...  datascientist  \n",
       "2  The Applied Research Center for Environment & ...  datascientist  \n",
       "3  Overview:\\nElement has an opportunity for a Ad...  datascientist  \n",
       "4  We are looking for a Data Scientist to design ...  datascientist  \n",
       "5  Our Client\\nWe are partnered with one of the l...  datascientist  \n",
       "6  The new construction of site improvements and ...  datascientist  \n",
       "7  As a KSA Intermediate Terrestrial Ecologist II...  datascientist  \n",
       "8  Company : Worley\\nPrimary Location\\n: SAU-ARD-...  datascientist  \n",
       "9  Company : Worley\\nPrimary Location\\n: SAU-ARD-...  datascientist  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf22adb",
   "metadata": {
    "papermill": {
     "duration": 0.002668,
     "end_time": "2025-11-27T06:44:30.228985",
     "exception": false,
     "start_time": "2025-11-27T06:44:30.226317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- using richer dataset!\n",
    "- Collect Persian (Multilingual language)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55caac30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:44:30.235855Z",
     "iopub.status.busy": "2025-11-27T06:44:30.235293Z",
     "iopub.status.idle": "2025-11-27T06:44:32.521015Z",
     "shell.execute_reply": "2025-11-27T06:44:32.519750Z"
    },
    "papermill": {
     "duration": 2.290827,
     "end_time": "2025-11-27T06:44:32.522445",
     "exception": false,
     "start_time": "2025-11-27T06:44:30.231618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Starting text cleaning process...\n",
      "‚úÖ Text cleaning completed.\n",
      "\n",
      "==================================================\n",
      "üîç Comparison: Raw vs Cleaned\n",
      "==================================================\n",
      "--- ORIGINAL DESC ---\n",
      "Overview:\n",
      "Element has an opportunity for a Chemistry Technician for testing, sample preparation and delivery/collection of samples and preparation of test reports\n",
      "\n",
      "This position will be based in Dammam , KSA\n",
      "\n",
      "Responsibilities:\n",
      "Analysis of water, soil, aggregates, concrete and scale samples ,operatin...\n",
      "\n",
      "--- CLEANED DESC ---\n",
      "overview element opportunity chemistry technician testing sample preparation delivery collection samples preparation test reports position based dammam ksa responsibilities analysis water soil aggregates concrete scale samples operating equipments like ph ec tds meters uv visible spectrophotometers ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 1. Download necessary NLTK resources\n",
    "# (If you are running this offline, you might need to download these manually once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 2. Define the cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies the following pre-processing steps:\n",
    "    1. Lowercasing\n",
    "    2. Removing HTML tags\n",
    "    3. Removing non-ASCII characters\n",
    "    4. Substitution (removing newlines/tabs)\n",
    "    5. Removing punctuation\n",
    "    6. Removing stop words\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing HTML tags (Regex to find <...>)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Removing non-ASCII characters (Keep only standard characters)\n",
    "    # This removes emojis or weird formatting characters\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r' ', text)\n",
    "    \n",
    "    # Substitution (Replace newlines \\n and tabs \\t with a single space)\n",
    "    text = re.sub(r'[\\r\\n\\t]+', ' ', text)\n",
    "    \n",
    "    # Removing Punctuation\n",
    "    # We replace punctuation with spaces to avoid merging words (e.g. \"hello/world\" -> \"hello world\")\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    \n",
    "    # F. Removing Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Tokenize by splitting on whitespace\n",
    "    words = text.split()\n",
    "    # Filter out stop words\n",
    "    filtered_words = [w for w in words if w not in stop_words]\n",
    "    \n",
    "    # Join back into a single string\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# 3. Apply the function to the 'desc' column\n",
    "print(\"üßπ Starting text cleaning process...\")\n",
    "\n",
    "# We create a NEW column 'cleaned_desc' to preserve the original data for comparison\n",
    "full_df['cleaned_desc'] = full_df['desc'].apply(clean_text)\n",
    "\n",
    "print(\"‚úÖ Text cleaning completed.\")\n",
    "\n",
    "# 4. Verify the results (Compare Before vs After)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üîç Comparison: Raw vs Cleaned\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# displaying the first valid entry\n",
    "sample_row = full_df.iloc[0]\n",
    "print(f\"--- ORIGINAL DESC ---\\n{sample_row['desc'][:300]}...\") # Show first 300 chars\n",
    "print(f\"\\n--- CLEANED DESC ---\\n{sample_row['cleaned_desc'][:300]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a8f388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T06:44:32.530414Z",
     "iopub.status.busy": "2025-11-27T06:44:32.529954Z",
     "iopub.status.idle": "2025-11-27T06:44:50.433937Z",
     "shell.execute_reply": "2025-11-27T06:44:50.432827Z"
    },
    "papermill": {
     "duration": 17.909956,
     "end_time": "2025-11-27T06:44:50.435632",
     "exception": false,
     "start_time": "2025-11-27T06:44:32.525676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base Model Loaded.\n",
      "‚úÖ Custom Rules Applied to Pipeline.\n",
      "\n",
      "üîç Extracting Entities from Job Descriptions...\n",
      "\n",
      "==================================================\n",
      "VALIDATED ENTITY EXTRACTION RESULTS\n",
      "==================================================\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('data science', 'SKILL'), ('data scientist', 'ROLE'), ('python', 'SKILL'), ('phd', 'DEGREE'), ('sql', 'SKILL')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('python', 'SKILL')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('bachelor', 'DEGREE')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('data science', 'SKILL'), ('big data', 'SKILL'), ('tensorflow', 'SKILL'), ('data scientist', 'ROLE'), ('machine learning', 'SKILL'), ('deep learning', 'SKILL'), ('pandas', 'SKILL'), ('python', 'SKILL'), ('bachelor', 'DEGREE'), ('java', 'SKILL'), ('computer science', 'DEGREE')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('data science', 'SKILL'), ('data scientist', 'ROLE'), ('python', 'SKILL'), ('phd', 'DEGREE'), ('sql', 'SKILL')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('bachelor', 'DEGREE')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('machine learning', 'SKILL'), ('python', 'SKILL'), ('master', 'DEGREE'), ('sql', 'SKILL')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('bachelor', 'DEGREE')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('bachelor', 'DEGREE')]\n",
      "------------------------------\n",
      "CATEGORY: datascientist\n",
      "FOUND:    [('bachelor', 'DEGREE')]\n",
      "------------------------------\n",
      "\n",
      "üìä STATS:\n",
      "Total Skills Identified: 105\n",
      "Most Common Skills: {'java': 20, 'python': 17, 'sql': 16, 'php': 8, 'javascript': 7}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "import pandas as pd\n",
    "\n",
    "# 1. INITIALIZE A PRE-TRAINED MODEL\n",
    "# instead of spacy.blank(\"en\"), we load the small English model\n",
    "# This helps because it already handles tokenization perfectly.\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    # Fallback if model isn't downloaded\n",
    "    print(\"Downloading model...\")\n",
    "    import os\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"‚úÖ Base Model Loaded.\")\n",
    "\n",
    "# 2. DEFINE YOUR KNOWLEDGE BASE (The \"Rules\")\n",
    "# We explicitly tell the AI what skills and roles look like.\n",
    "# In a real production system, this list comes from a database.\n",
    "skill_patterns = [\n",
    "    # Programming Languages\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"python\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"java\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"php\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"c++\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"sql\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"javascript\"}]},\n",
    "    \n",
    "    # Frameworks & Tools\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"aws\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"react\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"django\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"laravel\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"docker\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"kubernetes\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"tensorflow\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"pytorch\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"pandas\"}]},\n",
    "\n",
    "    # Concepts\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"deep\"}, {\"LOWER\": \"learning\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}]},\n",
    "    {\"label\": \"SKILL\", \"pattern\": [{\"LOWER\": \"big\"}, {\"LOWER\": \"data\"}]},\n",
    "]\n",
    "\n",
    "role_patterns = [\n",
    "    {\"label\": \"ROLE\", \"pattern\": [{\"LOWER\": \"data\"}, {\"LOWER\": \"scientist\"}]},\n",
    "    {\"label\": \"ROLE\", \"pattern\": [{\"LOWER\": \"software\"}, {\"LOWER\": \"engineer\"}]},\n",
    "    {\"label\": \"ROLE\", \"pattern\": [{\"LOWER\": \"backend\"}, {\"LOWER\": \"developer\"}]},\n",
    "    {\"label\": \"ROLE\", \"pattern\": [{\"LOWER\": \"frontend\"}, {\"LOWER\": \"developer\"}]},\n",
    "    {\"label\": \"ROLE\", \"pattern\": [{\"LOWER\": \"php\"}, {\"LOWER\": \"developer\"}]},\n",
    "    {\"label\": \"ROLE\", \"pattern\": [{\"LOWER\": \"java\"}, {\"LOWER\": \"developer\"}]},\n",
    "]\n",
    "\n",
    "degree_patterns = [\n",
    "    {\"label\": \"DEGREE\", \"pattern\": [{\"LOWER\": \"bachelor\"}]},\n",
    "    {\"label\": \"DEGREE\", \"pattern\": [{\"LOWER\": \"master\"}]},\n",
    "    {\"label\": \"DEGREE\", \"pattern\": [{\"LOWER\": \"phd\"}]},\n",
    "    {\"label\": \"DEGREE\", \"pattern\": [{\"LOWER\": \"computer\"}, {\"LOWER\": \"science\"}]},\n",
    "]\n",
    "\n",
    "# Combine all patterns\n",
    "all_patterns = skill_patterns + role_patterns + degree_patterns\n",
    "\n",
    "# 3. ADD THE RULER TO THE PIPELINE\n",
    "# This inserts our rules before the standard NER, giving them priority.\n",
    "if \"entity_ruler\" not in nlp.pipe_names:\n",
    "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "    ruler.add_patterns(all_patterns)\n",
    "\n",
    "print(\"‚úÖ Custom Rules Applied to Pipeline.\")\n",
    "\n",
    "# 4. APPLY TO DATASET\n",
    "def extract_clean_entities(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Filter: We only want entities that match OUR labels (SKILL, ROLE, DEGREE)\n",
    "    # We ignore standard spaCy labels like \"DATE\" or \"ORG\" to reduce noise\n",
    "    target_labels = [\"SKILL\", \"ROLE\", \"DEGREE\"]\n",
    "    \n",
    "    results = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in target_labels:\n",
    "            results.append((ent.text, ent.label_))\n",
    "            \n",
    "    return list(set(results)) # set() removes duplicates like ('Java', 'SKILL') appearing twice\n",
    "\n",
    "print(\"\\nüîç Extracting Entities from Job Descriptions...\")\n",
    "full_df['extracted_entities'] = full_df['cleaned_desc'].apply(extract_clean_entities)\n",
    "\n",
    "# 5. VIEW VALIDATED RESULTS\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATED ENTITY EXTRACTION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show rows that actually have entities found\n",
    "sample_rows = full_df[full_df['extracted_entities'].map(len) > 0].head(10)\n",
    "\n",
    "for index, row in sample_rows.iterrows():\n",
    "    print(f\"CATEGORY: {row['category']}\")\n",
    "    print(f\"FOUND:    {row['extracted_entities']}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Calculate Stats for the Paper\n",
    "all_skills = [ent[0] for sublist in full_df['extracted_entities'] for ent in sublist if ent[1] == 'SKILL']\n",
    "print(f\"\\nüìä STATS:\")\n",
    "print(f\"Total Skills Identified: {len(all_skills)}\")\n",
    "print(f\"Most Common Skills: {pd.Series(all_skills).value_counts().head(5).to_dict()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8835435,
     "sourceId": 13867576,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.151314,
   "end_time": "2025-11-27T06:44:52.870365",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-27T06:44:23.719051",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
